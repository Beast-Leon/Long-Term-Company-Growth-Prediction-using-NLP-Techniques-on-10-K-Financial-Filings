{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a90c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c69d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>ticker</th>\n",
       "      <th>abnormal_return</th>\n",
       "      <th>y</th>\n",
       "      <th>volatility</th>\n",
       "      <th>reaction_positive</th>\n",
       "      <th>reaction_negative</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_mfi</th>\n",
       "      <th>...</th>\n",
       "      <th>item7_polarity</th>\n",
       "      <th>item7_subjectivity</th>\n",
       "      <th>industry_B</th>\n",
       "      <th>industry_C</th>\n",
       "      <th>industry_D</th>\n",
       "      <th>industry_E</th>\n",
       "      <th>industry_F</th>\n",
       "      <th>industry_G</th>\n",
       "      <th>industry_H</th>\n",
       "      <th>industry_I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>nwpx</td>\n",
       "      <td>0.635924</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062822</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>-3.515938e+05</td>\n",
       "      <td>50.359009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519824</td>\n",
       "      <td>0.313428</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>nwpx</td>\n",
       "      <td>0.026142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147784</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.440436e+06</td>\n",
       "      <td>57.280553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.326236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>nwpx</td>\n",
       "      <td>-0.762775</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180493</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.414003e+06</td>\n",
       "      <td>53.844115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490050</td>\n",
       "      <td>0.307105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>nwpx</td>\n",
       "      <td>0.210231</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075963</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.214262e+06</td>\n",
       "      <td>50.947005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429119</td>\n",
       "      <td>0.321627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>nwpx</td>\n",
       "      <td>-0.013295</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161627</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.860406e+06</td>\n",
       "      <td>49.961210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.309386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  time ticker  abnormal_return  y  volatility  reaction_positive  \\\n",
       "0           0  2006   nwpx         0.635924  1    0.062822                  5   \n",
       "1           1  2007   nwpx         0.026142  1    0.147784                  5   \n",
       "2           2  2008   nwpx        -0.762775  0    0.180493                  3   \n",
       "3           3  2010   nwpx         0.210231  1    0.075963                 10   \n",
       "4           4  2011   nwpx        -0.013295  0    0.161627                  6   \n",
       "\n",
       "   reaction_negative    volume_adi  volume_mfi  ...  item7_polarity  \\\n",
       "0                  6 -3.515938e+05   50.359009  ...        0.519824   \n",
       "1                  6 -1.440436e+06   57.280553  ...        0.487179   \n",
       "2                  8 -1.414003e+06   53.844115  ...        0.490050   \n",
       "3                  1 -4.214262e+06   50.947005  ...        0.429119   \n",
       "4                  5 -4.860406e+06   49.961210  ...        0.500000   \n",
       "\n",
       "   item7_subjectivity  industry_B  industry_C  industry_D  industry_E  \\\n",
       "0            0.313428           0           0           1           0   \n",
       "1            0.326236           0           0           1           0   \n",
       "2            0.307105           0           0           1           0   \n",
       "3            0.321627           0           0           1           0   \n",
       "4            0.309386           0           0           1           0   \n",
       "\n",
       "   industry_F  industry_G  industry_H  industry_I  \n",
       "0           0           0           0           0  \n",
       "1           0           0           0           0  \n",
       "2           0           0           0           0  \n",
       "3           0           0           0           0  \n",
       "4           0           0           0           0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"final_v5_dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0529b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_mfi</th>\n",
       "      <th>volatility_atr</th>\n",
       "      <th>trend_sma_slow</th>\n",
       "      <th>trend_macd</th>\n",
       "      <th>momentum_rsi</th>\n",
       "      <th>momentum_roc</th>\n",
       "      <th>momentum_ppo</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>...</th>\n",
       "      <th>risk_factor_len</th>\n",
       "      <th>item1_pos</th>\n",
       "      <th>item1_neg</th>\n",
       "      <th>item1_polarity</th>\n",
       "      <th>item1_subjectivity</th>\n",
       "      <th>item1_len</th>\n",
       "      <th>item7_pos</th>\n",
       "      <th>item7_neg</th>\n",
       "      <th>item7_polarity</th>\n",
       "      <th>item7_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.515938e+05</td>\n",
       "      <td>50.359009</td>\n",
       "      <td>0.792847</td>\n",
       "      <td>28.379537</td>\n",
       "      <td>0.178588</td>\n",
       "      <td>53.106931</td>\n",
       "      <td>1.249287</td>\n",
       "      <td>0.585889</td>\n",
       "      <td>0.090921</td>\n",
       "      <td>115.647695</td>\n",
       "      <td>...</td>\n",
       "      <td>1789</td>\n",
       "      <td>438</td>\n",
       "      <td>174</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.277174</td>\n",
       "      <td>2897</td>\n",
       "      <td>690</td>\n",
       "      <td>218</td>\n",
       "      <td>0.519824</td>\n",
       "      <td>0.313428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.440436e+06</td>\n",
       "      <td>57.280553</td>\n",
       "      <td>1.412616</td>\n",
       "      <td>35.654050</td>\n",
       "      <td>0.098563</td>\n",
       "      <td>51.766881</td>\n",
       "      <td>0.861268</td>\n",
       "      <td>0.262177</td>\n",
       "      <td>0.060567</td>\n",
       "      <td>169.417288</td>\n",
       "      <td>...</td>\n",
       "      <td>1731</td>\n",
       "      <td>441</td>\n",
       "      <td>178</td>\n",
       "      <td>0.424879</td>\n",
       "      <td>0.276957</td>\n",
       "      <td>2630</td>\n",
       "      <td>638</td>\n",
       "      <td>220</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.326236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.414003e+06</td>\n",
       "      <td>53.844115</td>\n",
       "      <td>2.589620</td>\n",
       "      <td>43.180485</td>\n",
       "      <td>-0.106460</td>\n",
       "      <td>52.458817</td>\n",
       "      <td>1.131071</td>\n",
       "      <td>-0.514644</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>223.662843</td>\n",
       "      <td>...</td>\n",
       "      <td>1760</td>\n",
       "      <td>354</td>\n",
       "      <td>139</td>\n",
       "      <td>0.436105</td>\n",
       "      <td>0.268519</td>\n",
       "      <td>2618</td>\n",
       "      <td>599</td>\n",
       "      <td>205</td>\n",
       "      <td>0.490050</td>\n",
       "      <td>0.307105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.214262e+06</td>\n",
       "      <td>50.947005</td>\n",
       "      <td>0.922209</td>\n",
       "      <td>21.281775</td>\n",
       "      <td>-0.128362</td>\n",
       "      <td>48.554472</td>\n",
       "      <td>-0.209447</td>\n",
       "      <td>-0.584321</td>\n",
       "      <td>-0.044181</td>\n",
       "      <td>58.650848</td>\n",
       "      <td>...</td>\n",
       "      <td>3280</td>\n",
       "      <td>362</td>\n",
       "      <td>136</td>\n",
       "      <td>0.453815</td>\n",
       "      <td>0.260733</td>\n",
       "      <td>3246</td>\n",
       "      <td>746</td>\n",
       "      <td>298</td>\n",
       "      <td>0.429119</td>\n",
       "      <td>0.321627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.860406e+06</td>\n",
       "      <td>49.961210</td>\n",
       "      <td>1.204679</td>\n",
       "      <td>24.127654</td>\n",
       "      <td>0.026656</td>\n",
       "      <td>50.792482</td>\n",
       "      <td>0.489925</td>\n",
       "      <td>0.078676</td>\n",
       "      <td>-0.019807</td>\n",
       "      <td>81.374244</td>\n",
       "      <td>...</td>\n",
       "      <td>3232</td>\n",
       "      <td>388</td>\n",
       "      <td>142</td>\n",
       "      <td>0.464151</td>\n",
       "      <td>0.269857</td>\n",
       "      <td>3271</td>\n",
       "      <td>759</td>\n",
       "      <td>253</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.309386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>-2.201136e+10</td>\n",
       "      <td>47.417896</td>\n",
       "      <td>40.392765</td>\n",
       "      <td>155.499941</td>\n",
       "      <td>-0.563620</td>\n",
       "      <td>48.492309</td>\n",
       "      <td>-0.597432</td>\n",
       "      <td>-0.418673</td>\n",
       "      <td>-0.059587</td>\n",
       "      <td>582.131185</td>\n",
       "      <td>...</td>\n",
       "      <td>5767</td>\n",
       "      <td>806</td>\n",
       "      <td>274</td>\n",
       "      <td>0.492593</td>\n",
       "      <td>0.275089</td>\n",
       "      <td>10680</td>\n",
       "      <td>2269</td>\n",
       "      <td>1014</td>\n",
       "      <td>0.382272</td>\n",
       "      <td>0.307397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>-2.638618e+10</td>\n",
       "      <td>59.570540</td>\n",
       "      <td>40.465728</td>\n",
       "      <td>160.913902</td>\n",
       "      <td>1.485700</td>\n",
       "      <td>57.344488</td>\n",
       "      <td>1.629953</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>0.112526</td>\n",
       "      <td>622.867336</td>\n",
       "      <td>...</td>\n",
       "      <td>6561</td>\n",
       "      <td>922</td>\n",
       "      <td>280</td>\n",
       "      <td>0.534110</td>\n",
       "      <td>0.272501</td>\n",
       "      <td>8273</td>\n",
       "      <td>1710</td>\n",
       "      <td>826</td>\n",
       "      <td>0.348580</td>\n",
       "      <td>0.306539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5392</th>\n",
       "      <td>-3.219974e+10</td>\n",
       "      <td>49.605018</td>\n",
       "      <td>38.301655</td>\n",
       "      <td>306.367418</td>\n",
       "      <td>1.477140</td>\n",
       "      <td>54.232824</td>\n",
       "      <td>1.026203</td>\n",
       "      <td>0.496825</td>\n",
       "      <td>0.074632</td>\n",
       "      <td>1265.705500</td>\n",
       "      <td>...</td>\n",
       "      <td>7649</td>\n",
       "      <td>999</td>\n",
       "      <td>241</td>\n",
       "      <td>0.611290</td>\n",
       "      <td>0.267472</td>\n",
       "      <td>9157</td>\n",
       "      <td>1845</td>\n",
       "      <td>907</td>\n",
       "      <td>0.340843</td>\n",
       "      <td>0.300535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393</th>\n",
       "      <td>-3.375959e+10</td>\n",
       "      <td>56.892858</td>\n",
       "      <td>38.925276</td>\n",
       "      <td>388.472880</td>\n",
       "      <td>3.048024</td>\n",
       "      <td>58.235279</td>\n",
       "      <td>1.317394</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>0.102055</td>\n",
       "      <td>1638.409575</td>\n",
       "      <td>...</td>\n",
       "      <td>7793</td>\n",
       "      <td>966</td>\n",
       "      <td>246</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>0.263995</td>\n",
       "      <td>9050</td>\n",
       "      <td>1781</td>\n",
       "      <td>874</td>\n",
       "      <td>0.341620</td>\n",
       "      <td>0.293370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>-3.490552e+10</td>\n",
       "      <td>49.034877</td>\n",
       "      <td>31.464097</td>\n",
       "      <td>390.052452</td>\n",
       "      <td>-1.844123</td>\n",
       "      <td>47.520759</td>\n",
       "      <td>-0.859490</td>\n",
       "      <td>-0.489208</td>\n",
       "      <td>-0.090968</td>\n",
       "      <td>1607.804234</td>\n",
       "      <td>...</td>\n",
       "      <td>7631</td>\n",
       "      <td>994</td>\n",
       "      <td>258</td>\n",
       "      <td>0.587859</td>\n",
       "      <td>0.277052</td>\n",
       "      <td>8622</td>\n",
       "      <td>1707</td>\n",
       "      <td>868</td>\n",
       "      <td>0.325825</td>\n",
       "      <td>0.298655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5395 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        volume_adi  volume_mfi  volatility_atr  trend_sma_slow  trend_macd  \\\n",
       "0    -3.515938e+05   50.359009        0.792847       28.379537    0.178588   \n",
       "1    -1.440436e+06   57.280553        1.412616       35.654050    0.098563   \n",
       "2    -1.414003e+06   53.844115        2.589620       43.180485   -0.106460   \n",
       "3    -4.214262e+06   50.947005        0.922209       21.281775   -0.128362   \n",
       "4    -4.860406e+06   49.961210        1.204679       24.127654    0.026656   \n",
       "...            ...         ...             ...             ...         ...   \n",
       "5390 -2.201136e+10   47.417896       40.392765      155.499941   -0.563620   \n",
       "5391 -2.638618e+10   59.570540       40.465728      160.913902    1.485700   \n",
       "5392 -3.219974e+10   49.605018       38.301655      306.367418    1.477140   \n",
       "5393 -3.375959e+10   56.892858       38.925276      388.472880    3.048024   \n",
       "5394 -3.490552e+10   49.034877       31.464097      390.052452   -1.844123   \n",
       "\n",
       "      momentum_rsi  momentum_roc  momentum_ppo  others_dlr    others_cr  ...  \\\n",
       "0        53.106931      1.249287      0.585889    0.090921   115.647695  ...   \n",
       "1        51.766881      0.861268      0.262177    0.060567   169.417288  ...   \n",
       "2        52.458817      1.131071     -0.514644    0.033575   223.662843  ...   \n",
       "3        48.554472     -0.209447     -0.584321   -0.044181    58.650848  ...   \n",
       "4        50.792482      0.489925      0.078676   -0.019807    81.374244  ...   \n",
       "...            ...           ...           ...         ...          ...  ...   \n",
       "5390     48.492309     -0.597432     -0.418673   -0.059587   582.131185  ...   \n",
       "5391     57.344488      1.629953      0.909879    0.112526   622.867336  ...   \n",
       "5392     54.232824      1.026203      0.496825    0.074632  1265.705500  ...   \n",
       "5393     58.235279      1.317394      0.816853    0.102055  1638.409575  ...   \n",
       "5394     47.520759     -0.859490     -0.489208   -0.090968  1607.804234  ...   \n",
       "\n",
       "      risk_factor_len  item1_pos  item1_neg  item1_polarity  \\\n",
       "0                1789        438        174        0.431373   \n",
       "1                1731        441        178        0.424879   \n",
       "2                1760        354        139        0.436105   \n",
       "3                3280        362        136        0.453815   \n",
       "4                3232        388        142        0.464151   \n",
       "...               ...        ...        ...             ...   \n",
       "5390             5767        806        274        0.492593   \n",
       "5391             6561        922        280        0.534110   \n",
       "5392             7649        999        241        0.611290   \n",
       "5393             7793        966        246        0.594059   \n",
       "5394             7631        994        258        0.587859   \n",
       "\n",
       "      item1_subjectivity  item1_len  item7_pos  item7_neg  item7_polarity  \\\n",
       "0               0.277174       2897        690        218        0.519824   \n",
       "1               0.276957       2630        638        220        0.487179   \n",
       "2               0.268519       2618        599        205        0.490050   \n",
       "3               0.260733       3246        746        298        0.429119   \n",
       "4               0.269857       3271        759        253        0.500000   \n",
       "...                  ...        ...        ...        ...             ...   \n",
       "5390            0.275089      10680       2269       1014        0.382272   \n",
       "5391            0.272501       8273       1710        826        0.348580   \n",
       "5392            0.267472       9157       1845        907        0.340843   \n",
       "5393            0.263995       9050       1781        874        0.341620   \n",
       "5394            0.277052       8622       1707        868        0.325825   \n",
       "\n",
       "      item7_subjectivity  \n",
       "0               0.313428  \n",
       "1               0.326236  \n",
       "2               0.307105  \n",
       "3               0.321627  \n",
       "4               0.309386  \n",
       "...                  ...  \n",
       "5390            0.307397  \n",
       "5391            0.306539  \n",
       "5392            0.300535  \n",
       "5393            0.293370  \n",
       "5394            0.298655  \n",
       "\n",
       "[5395 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data['y']\n",
    "X=data.iloc[:,8:32]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde6e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing for imbalanced data \n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE \n",
    "standardizer = StandardScaler()\n",
    "sm = SMOTE(random_state=42) \n",
    "X_sm, y_sm = sm.fit_resample(X, y) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm,test_size = 0.2,random_state = 150)\n",
    "standardizer.fit(X_train) \n",
    "X_train = standardizer.transform(X_train) \n",
    "X_test = standardizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1438294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=5, scoring_fit='accuracy', \n",
    "                       scoring_test=accuracy_score):\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        # n_jobs=4, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=1\n",
    "    )    \n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "    best_model = fitted_model.best_estimator_\n",
    "    pred = fitted_model.predict(X_test_data)\n",
    "    score = scoring_test(y_test_data, pred)\n",
    "    \n",
    "    return [best_model, pred, score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b96738bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = [\n",
    "    { # xgb  \n",
    "        #'n_estimators': [200,220,240,260],\n",
    "        #'max_depth': [8,9,10,11,12], \n",
    "        #'min_child_weight':range(1,10,2)\n",
    "        #'gamma':[i/10.0 for i in range(0,5)]\n",
    "        #'subsample':[0.9,1],\n",
    "        #'colsample_bytree':[0.9,1],\n",
    "        #'reg_alpha':[0,0.01,0.015,0.02],\n",
    "        #'eta':[0.15,0.2,0.25]\n",
    "    }, \n",
    "    { # lgbm\n",
    "        #'n_estimators': [i*20 for i in range(5,11)],\n",
    "        #'max_depth': [i for i in range(6,10)],\n",
    "        #'min_child_weight':range(1,10,2)\n",
    "        #'reg_alpha': [0,0.05,0.1],\n",
    "        #'learning_rate':[0.05,0.1,0.15]\n",
    "    }, \n",
    "    \n",
    "    { # randomforest\n",
    "        #'n_estimators': [200,220,240,260],\n",
    "        #'max_depth': [9,10,11,12], \n",
    "        #'max_features': [3,4,5,6],\n",
    "        #'min_samples_leaf': [3, 4, 5],\n",
    "        #'min_samples_split': [3,4,5,6]\n",
    "    },\n",
    "    { # dt\n",
    "        #'criterion': ['gini', 'entropy'],\n",
    "        #'max_depth': [9,10,11,12],\n",
    "        #'splitter': ['best', 'random'],\n",
    "        #'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "        \n",
    "    },\n",
    "    { # gradient boost\n",
    "        #'n_estimators': [200,220,240,260],\n",
    "        #'max_depth': [8,9,10,11,12],\n",
    "        #'min_samples_split':np.linspace(0.1, 1.0, 10, endpoint=True),\n",
    "        #'min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True),\n",
    "        #'max_features':list(range(1,35,3)),\n",
    "        #'learning_rate':[0.15,0.2,0.25]\n",
    "    },\n",
    " \n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train = [xgb.XGBClassifier(eval_metric=['logloss','auc','error'],use_label_encoder=False,random_state = 88), \n",
    "                   lgb.LGBMClassifier(random_state = 88), RandomForestClassifier(random_state = 88),\n",
    "                   DecisionTreeClassifier(random_state = 88),  GradientBoostingClassifier(random_state = 88) ]\n",
    "#best_model, pred, score\n",
    "models_preds_scores = []\n",
    "\n",
    "# loop through each model, 4 in this case\n",
    "for i, model in enumerate(models_to_train):\n",
    "    params = grid_parameters[i]\n",
    "    \n",
    "    result = algorithm_pipeline(X_train, X_test, y_train, y_test,\n",
    "                                 model, params, cv=5)\n",
    "    models_preds_scores.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aecddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in models_preds_scores:\n",
    "    print('Model: {0}, Score: {1}'.format(result[0], result[2]))\n",
    "xgb_classifier = models_preds_scores[0][0]\n",
    "lgbm_classifier = models_preds_scores[1][0]\n",
    "rf_classifier = models_preds_scores[2][0]\n",
    "tree_classifier = models_preds_scores[3][0]\n",
    "gb_classifier= models_preds_scores[4][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15fbd0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=12, n_estimators=260, random_state=88)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, eta=0.15,\n",
    "              eval_metric=['logloss', 'auc', 'error'], gamma=0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.150000006, max_delta_step=0, max_depth=11,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=260, n_jobs=10, num_parallel_tree=1, random_state=88,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None)\n",
    "xgb_classifier.fit(X_train,y_train)\n",
    "lgbm_classifier = lgb.LGBMClassifier(max_depth=7, min_child_weight=1, n_estimators=120,\n",
    "               random_state=88, reg_alpha=0)\n",
    "lgbm_classifier.fit(X_train,y_train)\n",
    "rf_classifier = RandomForestClassifier(max_depth=12, max_features=5, min_samples_leaf=4,\n",
    "                       n_estimators=200, random_state=88)\n",
    "rf_classifier.fit(X_train,y_train)\n",
    "tree_classifier =  DecisionTreeClassifier(min_samples_leaf=10,max_depth=12,random_state = 88,splitter='random')\n",
    "tree_classifier.fit(X_train,y_train)\n",
    "gb_classifier = GradientBoostingClassifier(max_depth=12, n_estimators=260,random_state = 88)\n",
    "gb_classifier.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f937571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6932153392330384, 0.6784660766961652, 0.6696165191740413, 0.6017699115044248, 0.7234513274336283]\n"
     ]
    }
   ],
   "source": [
    "def cal_score(model, X_test,y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, pred)\n",
    "    return accuracy\n",
    "modelscore = []\n",
    "modelscore.append(cal_score(xgb_classifier,X_test,y_test))\n",
    "modelscore.append(cal_score(lgbm_classifier,X_test,y_test))\n",
    "modelscore.append(cal_score(rf_classifier,X_test,y_test))\n",
    "modelscore.append(cal_score(tree_classifier,X_test,y_test))\n",
    "modelscore.append(cal_score(gb_classifier,X_test,y_test))\n",
    "print(modelscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac6234",
   "metadata": {},
   "source": [
    "method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c89a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "def get_model(model_level1):\n",
    "    \n",
    "    level0 = []\n",
    "    level0.append(('xgb', xgb_classifier))\n",
    "    level0.append(('lgbm', lgbm_classifier))\n",
    "    level0.append(('rf', rf_classifier))\n",
    "    level0.append(('cart', tree_classifier))\n",
    "    level0.append(('gb',gb_classifier))\n",
    "   \n",
    "    level1 = model_level1\n",
    "   \n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, X, y):\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):    \n",
    "    y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score\n",
    "\n",
    "stacking_model_1 = get_model(LogisticRegression())\n",
    "stacking_model_1 = train_model(stacking_model_1, X_train, y_train)\n",
    "\n",
    "score_1 = evaluate_model(stacking_model_1, X_test, y_test)\n",
    "#print('Score of stacking model:', score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7309a657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of stacking model: 0.7345132743362832\n"
     ]
    }
   ],
   "source": [
    "print('Score of stacking model:', score_1)\n",
    "# 0.7345132743362832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae9e1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'kernel': ['poly', 'rbf', 'sigmoid'], # you shoul duse only rbf, here is for illustration purpose \n",
    "#'C': [50, 10, 1.0, 0.1, 0.01], # There are two parameters, tune C carefully. (Gamma is decided by 'scale' option)\n",
    "#'gamma': ['scale']\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "score = []\n",
    "for i in [10,1,0.1]:\n",
    "    stacking_model_2 = get_model(SVC(kernel = 'rbf',C=i, gamma = 'scale'))\n",
    "    stacking_model_2 = train_model(stacking_model_2, X_train, y_train)\n",
    "\n",
    "    score_2 = evaluate_model(stacking_model_2, X_test, y_test)\n",
    "    score.append(score_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d90f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of stacking model: [0.7389380530973452, 0.7382005899705014, 0.7418879056047197]\n"
     ]
    }
   ],
   "source": [
    "print('Score of stacking model:', score)\n",
    "#0.7389380530973452,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57db21d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: 0.727139\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "stack_classifier = StackingClassifier(classifiers=[xgb_classifier, lgbm_classifier, rf_classifier,tree_classifier,gb_classifier], \n",
    "                                     meta_classifier=LogisticRegression())\n",
    "\n",
    "stack_classifier.fit(X_train, y_train)\n",
    "y_pred = stack_classifier.predict(X_test)\n",
    "print('Final prediction score: %f' % accuracy_score(y_test, y_pred))\n",
    "#0.727139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33cdb78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: 0.721976\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "stack_classifier = StackingClassifier(classifiers=[xgb_classifier, lgbm_classifier,rf_classifier,tree_classifier,gb_classifier], \n",
    "                                     meta_classifier=SVC(kernel = 'rbf',C=10, gamma = 'scale'))\n",
    "\n",
    "stack_classifier.fit(X_train, y_train)\n",
    "y_pred = stack_classifier.predict(X_test)\n",
    "print('Final prediction score: %f' % accuracy_score(y_test, y_pred))\n",
    "#0.721976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b581c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import stacking\n",
    "level0_models = [xgb_classifier, lgbm_classifier, rf_classifier,tree_classifier,gb_classifier]\n",
    "S_train, S_test = stacking(level0_models, X_train, y_train, X_test, regression=False,\n",
    "                           mode='oof_pred_bag', needs_proba=False, save_dir=None,\n",
    "                           metric=accuracy_score, n_folds=5,  stratified=True,\n",
    "                           shuffle=True, random_state=0, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ae6ed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: 0.729351\n"
     ]
    }
   ],
   "source": [
    "level1_model = LogisticRegression()\n",
    "\n",
    "level1_model = level1_model.fit(S_train, y_train)\n",
    "y_pred = level1_model.predict(S_test)\n",
    "print('Final prediction score: %f' % accuracy_score(y_test, y_pred))\n",
    "#0.729351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe85e2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: 0.726401\n"
     ]
    }
   ],
   "source": [
    "level1_model = SVC(kernel = 'rbf',C=1, gamma = 'scale')\n",
    "\n",
    "level1_model = level1_model.fit(S_train, y_train)\n",
    "y_pred = level1_model.predict(S_test)\n",
    "print('Final prediction score: %f' % accuracy_score(y_test, y_pred))\n",
    "#0.726401"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a8338",
   "metadata": {},
   "source": [
    "method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b727f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "#olds = StratifiedKFold(n_splits = 5)\n",
    "def get_oof(clf ,x_train, y_train, x_test, n_folds = 5):\n",
    "    \"\"\"K-fold stacking\"\"\"\n",
    "    ntrain = X_train.shape[0]\n",
    "    ntest =  X_test.shape[0]\n",
    "    classnum = len(np.unique(y_train))\n",
    "    oof_test_skf = np.empty((5, ntest))\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    oof_train = np.zeros((ntrain,classnum))\n",
    "    oof_test = np.zeros((ntest,classnum))\n",
    "        \n",
    "    for i,(train_index,test_index) in enumerate(kf.split(X_train)):\n",
    "        #print(type(train_index))\n",
    "        \n",
    "        kf_X_train = X_train[train_index] # 数据\n",
    "        kf_y_train = y_train[train_index] # 标签\n",
    "        \n",
    "        kf_X_test = X_train[test_index]  # k-fold的验证集\n",
    "        \n",
    "        clf.fit(kf_X_train, kf_y_train)\n",
    "        \n",
    "        oof_train[test_index] = clf.predict_proba(kf_X_test)\n",
    "        #oof_test_skf[i,:]=clf.predict_proba(X_test)[:,0]\n",
    "        oof_test += clf.predict_proba(X_test)\n",
    "    oof_test = oof_test/float(n_folds)\n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "420f1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new feature input level1\n",
    "import functools \n",
    "newfeature_list_1 = []\n",
    "newtestdata_list_1 = []\n",
    "xgb_oof_train_1, xgb_oof_test_1 = get_oof(xgb_classifier,X_train, y_train.values, X_test)\n",
    "newfeature_list_1.append(xgb_oof_train_1)\n",
    "newtestdata_list_1.append(xgb_oof_test_1)\n",
    "\n",
    "lgbm_oof_train_1, xgb_oof_test_1 = get_oof(lgbm_classifier,X_train, y_train.values, X_test)\n",
    "newfeature_list_1.append(lgbm_oof_train_1)\n",
    "newtestdata_list_1.append(xgb_oof_test_1)\n",
    "\n",
    "rf_oof_train_1, rf_oof_test_1 = get_oof(rf_classifier,X_train, y_train.values, X_test)\n",
    "newfeature_list_1.append(rf_oof_train_1)\n",
    "newtestdata_list_1.append(rf_oof_test_1)\n",
    "\n",
    "dt_oof_train_1, dt_oof_test_1 = get_oof(tree_classifier,X_train, y_train.values, X_test)\n",
    "newfeature_list_1.append(dt_oof_train_1)\n",
    "newtestdata_list_1.append(dt_oof_test_1)\n",
    "\n",
    "gb_oof_train_1, gb_oof_test_1 = get_oof(gb_classifier,X_train, y_train.values, X_test)\n",
    "newfeature_list_1.append(gb_oof_train_1)\n",
    "newtestdata_list_1.append(gb_oof_test_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f861bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "newfeature_1 = functools.reduce(lambda x,y:np.concatenate((x,y),axis=1),newfeature_list_1)    \n",
    "newtestdata_1 =functools.reduce(lambda x,y:np.concatenate((x,y),axis=1),newtestdata_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba3dd64e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7352507374631269\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(newfeature_1, y_train)\n",
    "pred_1 = lr.predict(newtestdata_1)\n",
    "accuracy_1 = accuracy_score(y_test, pred_1)\n",
    "print(accuracy_1)\n",
    "#0.7352507374631269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "615d20ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745575221238938\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svr = SVC(kernel = 'rbf',C=0.1, gamma = 'scale',probability=True)\n",
    "svr.fit(newfeature_1, y_train)\n",
    "pred_2 = svr.predict(newtestdata_1)\n",
    "accuracy_2 = accuracy_score(y_test, pred_2)\n",
    "print(accuracy_2)\n",
    "#0.745575221238938"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
